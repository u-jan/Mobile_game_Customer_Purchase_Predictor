{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: MVP\n",
    "\n",
    "I will include most features within the model as I try to identify couple of problems as well as improvement points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was having hard time to get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10k = pd.read_csv('data_the_babe/df_10k_ready_for_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9907, 130)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'adOption', 'daysSinceInstall', 'hasEnoughCoin',\n",
       "       'levelMode', 'levelNumber', 'numFails', 'percentageLeft', 'platform',\n",
       "       'playTime',\n",
       "       ...\n",
       "       'ZA', 'de', 'en', 'es', 'fr', 'it', 'pt-BR', 'ru', 'tr', 'zh-CN'],\n",
       "      dtype='object', length=130)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_10k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set target and predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']\n",
    "X = df.drop(['target'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_ratio = min(y.value_counts()) / len(y)\n",
    "failure_ratio = max(y.value_counts()) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have 3 potential targets which are not confirmed to be main and we can not have signal for positive predictions for any of them and that is due to unbalanced data. Luckily I came across a technique called SMOTE. \n",
    "\n",
    "SMOTE: There are a number of methods available to oversample a dataset used in a typical classification problem (using a classification algorithm to classify a set of images, given a labelled training set of images). The most common technique is known as SMOTE: Synthetic Minority Over-sampling Technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just want to increase my chances of having signal with SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SMOTE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  12046\n",
      "Number of no subscription in oversampled data 6023\n",
      "Number of subscription 6023\n",
      "Proportion of no subscription data in oversampled data is  0.5\n",
      "Proportion of subscription data in oversampled data is  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, df.columns != 'target']\n",
    "y = df.loc[:, df.columns == 'target']\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#train test split.\n",
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "os_data_X,os_data_y=os.fit_sample(X_train, y_train)  #as you can see we need to fit train data to os\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** You need to fit the oversampled data to the model when you use SMOTE. Since it increases the number of datapoints processing models will require more computational power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GradientBoostingClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another reminder, we need to train the oversampled data for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate = 0.01, n_estimators = 1000)\n",
    "gb.fit(os_data_X,os_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8644466868483014"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confusion matrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2482   89]\n",
      " [ 314   88]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.89      0.97      0.92      2571\n",
      "        True       0.50      0.22      0.30       402\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      2973\n",
      "   macro avg       0.69      0.59      0.61      2973\n",
      "weighted avg       0.83      0.86      0.84      2973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores look better compared to non-smoted model, yet I noticed that I made a ***deadly mistake***. Adwatch feature which is ~50% of the target, is 100%  dependent on one of the features called adoption, **Colinearity** . Certainly if players can not see ads they can not watch them. Which tells us that. Lets drop that and see the gradient boost scores again. I will leave the faulty model on the notebook in order to remind myself how damaging can it be to include mutually dependent features within the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['adOption'],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***SMOTE AFTER DROPPING adOption***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of oversampled data is  12046\n",
      "Number of no subscription in oversampled data 6023\n",
      "Number of subscription 6023\n",
      "Proportion of no subscription data in oversampled data is  0.5\n",
      "Proportion of subscription data in oversampled data is  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "X = X\n",
    "y = df.loc[:, df.columns == 'target']\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "columns = X_train.columns\n",
    "os_data_X,os_data_y=os.fit_sample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])\n",
    "\n",
    "# we can Check the numbers of our data\n",
    "print(\"length of oversampled data is \",len(os_data_X))\n",
    "print(\"Number of no subscription in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "print(\"Number of subscription\",len(os_data_y[os_data_y['y']==1]))\n",
    "print(\"Proportion of no subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "print(\"Proportion of subscription data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(learning_rate = 0.01, n_estimators = 1000)\n",
    "gb.fit(os_data_X,os_data_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2566    5]\n",
      " [ 394    8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      1.00      0.93      2571\n",
      "        True       0.62      0.02      0.04       402\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      2973\n",
      "   macro avg       0.74      0.51      0.48      2973\n",
      "weighted avg       0.83      0.87      0.81      2973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen the f1 score droped dramatically when we stoped tricking our model. In other words we still have a problem with receiving any signal. The model predicted positive for only 2% of the times and among that 2% the precision was only 62%.\n",
    "\n",
    "In other words a combined target with using the complete dataset does not help us at all with gradient boost classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to try a logistic regression model to see if I can reach a similar accuracy with enough number of features. \n",
    "\n",
    "Having noise with all features was a challange for me in past day, so I will get rid of the less important ones with RFE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***REF -- Recursive Feature Elimination***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False  True False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True False  True False False False  True False False False False\n",
      " False False False False  True False False False False False False  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False]\n",
      "[115   1 109   1  74 113 108 102 100 110 114  93  68  69  67  29 104  80\n",
      "  96  85  97 105 111 112 101 103  52  53 116  60   1  36  75  45   3  27\n",
      " 117  31   1  23  44  94  71  33  54  64  30  13   2 119  83  32   8  26\n",
      "  66  70  47  43  61  51  35   1  40 120   9 106  87  63  92  86   5  99\n",
      "  55  50  84  22  21  15  90  18  41  42  77  73 107   1  10   1  14   6\n",
      "  58   1   7  81  28  39  62  16  17  19   1  37  88 118  12  82  25   1\n",
      "  20  56  48  24  72  65  89  59  49  95  76   4  57  79  46  91  98  34\n",
      "  38  78  11]\n"
     ]
    }
   ],
   "source": [
    "data_final_vars= df.columns.values.tolist()\n",
    "y=['target']\n",
    "X=[i for i in data_final_vars if i not in y]\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg, 10)\n",
    "rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_bool = rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_chosen_rfe = np.array(X)[feature_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['adOption', 'hasEnoughCoin', 'AL', 'BD', 'GR', 'MU', 'MY', 'OM',\n",
       "       'RS', 'SY'], dtype='<U16')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_chosen_rfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the win and fail ratios at following. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13253255274048653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'target', data = df , palette = 'hls')\n",
    "plt.show()\n",
    "plt.savefig('count_target')\n",
    "print(success_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>adOption</th>\n",
       "      <th>daysSinceInstall</th>\n",
       "      <th>hasEnoughCoin</th>\n",
       "      <th>levelMode</th>\n",
       "      <th>levelNumber</th>\n",
       "      <th>numFails</th>\n",
       "      <th>percentageLeft</th>\n",
       "      <th>platform</th>\n",
       "      <th>playTime</th>\n",
       "      <th>...</th>\n",
       "      <th>ZA</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>pt-BR</th>\n",
       "      <th>ru</th>\n",
       "      <th>tr</th>\n",
       "      <th>zh-CN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>4934.644170</td>\n",
       "      <td>0.153130</td>\n",
       "      <td>71.834419</td>\n",
       "      <td>0.548755</td>\n",
       "      <td>0.857110</td>\n",
       "      <td>88.149290</td>\n",
       "      <td>6.084245</td>\n",
       "      <td>5.518036</td>\n",
       "      <td>0.497440</td>\n",
       "      <td>48.161741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.549337</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>0.02781</td>\n",
       "      <td>0.038283</td>\n",
       "      <td>0.021759</td>\n",
       "      <td>0.159646</td>\n",
       "      <td>0.167559</td>\n",
       "      <td>0.003258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>5073.144707</td>\n",
       "      <td>0.540746</td>\n",
       "      <td>60.666413</td>\n",
       "      <td>0.795126</td>\n",
       "      <td>0.843869</td>\n",
       "      <td>107.530845</td>\n",
       "      <td>5.738005</td>\n",
       "      <td>5.316832</td>\n",
       "      <td>0.449353</td>\n",
       "      <td>50.937548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022848</td>\n",
       "      <td>0.517898</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>0.02818</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.146992</td>\n",
       "      <td>0.211729</td>\n",
       "      <td>0.002285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  adOption  daysSinceInstall  hasEnoughCoin  levelMode  \\\n",
       "target                                                                      \n",
       "False   4934.644170  0.153130         71.834419       0.548755   0.857110   \n",
       "True    5073.144707  0.540746         60.666413       0.795126   0.843869   \n",
       "\n",
       "        levelNumber  numFails  percentageLeft  platform   playTime    ...     \\\n",
       "target                                                                ...      \n",
       "False     88.149290  6.084245        5.518036  0.497440  48.161741    ...      \n",
       "True     107.530845  5.738005        5.316832  0.449353  50.937548    ...      \n",
       "\n",
       "              ZA        de        en        es       fr        it     pt-BR  \\\n",
       "target                                                                        \n",
       "False   0.001164  0.017687  0.549337  0.014661  0.02781  0.038283  0.021759   \n",
       "True    0.000000  0.022848  0.517898  0.010663  0.02818  0.039604  0.019802   \n",
       "\n",
       "              ru        tr     zh-CN  \n",
       "target                                \n",
       "False   0.159646  0.167559  0.003258  \n",
       "True    0.146992  0.211729  0.002285  \n",
       "\n",
       "[2 rows x 129 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('target').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr = df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>adOption</th>\n",
       "      <th>daysSinceInstall</th>\n",
       "      <th>hasEnoughCoin</th>\n",
       "      <th>levelMode</th>\n",
       "      <th>levelNumber</th>\n",
       "      <th>numFails</th>\n",
       "      <th>percentageLeft</th>\n",
       "      <th>platform</th>\n",
       "      <th>playTime</th>\n",
       "      <th>...</th>\n",
       "      <th>ZA</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>pt-BR</th>\n",
       "      <th>ru</th>\n",
       "      <th>tr</th>\n",
       "      <th>zh-CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>-0.020841</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.014055</td>\n",
       "      <td>-0.031564</td>\n",
       "      <td>0.009165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024028</td>\n",
       "      <td>-0.017764</td>\n",
       "      <td>-0.022509</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.042495</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>-0.024485</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>0.014889</td>\n",
       "      <td>0.007735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adOption</th>\n",
       "      <td>-0.001869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.082626</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>-0.021917</td>\n",
       "      <td>-0.022779</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>-0.162144</td>\n",
       "      <td>-0.008135</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016117</td>\n",
       "      <td>0.010773</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>-0.017401</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>-0.037771</td>\n",
       "      <td>0.036795</td>\n",
       "      <td>-0.023926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daysSinceInstall</th>\n",
       "      <td>0.007306</td>\n",
       "      <td>-0.082626</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.159088</td>\n",
       "      <td>-0.225098</td>\n",
       "      <td>0.632715</td>\n",
       "      <td>0.153595</td>\n",
       "      <td>-0.016962</td>\n",
       "      <td>0.192754</td>\n",
       "      <td>0.119006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022902</td>\n",
       "      <td>0.065366</td>\n",
       "      <td>-0.041482</td>\n",
       "      <td>-0.023532</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>-0.000975</td>\n",
       "      <td>-0.044980</td>\n",
       "      <td>0.034922</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>0.027481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hasEnoughCoin</th>\n",
       "      <td>-0.020841</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>0.159088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.155804</td>\n",
       "      <td>0.411498</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.008117</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>0.037795</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>-0.002128</td>\n",
       "      <td>-0.028424</td>\n",
       "      <td>-0.034151</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>-0.016702</td>\n",
       "      <td>-0.027435</td>\n",
       "      <td>0.051418</td>\n",
       "      <td>0.032885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>levelMode</th>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.009286</td>\n",
       "      <td>-0.225098</td>\n",
       "      <td>-0.155804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.180247</td>\n",
       "      <td>-0.013784</td>\n",
       "      <td>-0.053117</td>\n",
       "      <td>-0.043799</td>\n",
       "      <td>0.038585</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023076</td>\n",
       "      <td>-0.037770</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.012765</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>0.038964</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>-0.021740</td>\n",
       "      <td>-0.006442</td>\n",
       "      <td>0.023039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>levelNumber</th>\n",
       "      <td>0.020190</td>\n",
       "      <td>-0.021917</td>\n",
       "      <td>0.632715</td>\n",
       "      <td>0.411498</td>\n",
       "      <td>-0.180247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>-0.009636</td>\n",
       "      <td>0.077311</td>\n",
       "      <td>0.222778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025313</td>\n",
       "      <td>0.068390</td>\n",
       "      <td>-0.055050</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>-0.019599</td>\n",
       "      <td>0.022720</td>\n",
       "      <td>-0.022659</td>\n",
       "      <td>-0.025153</td>\n",
       "      <td>0.078044</td>\n",
       "      <td>-0.004977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numFails</th>\n",
       "      <td>0.016578</td>\n",
       "      <td>-0.022779</td>\n",
       "      <td>0.153595</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>-0.013784</td>\n",
       "      <td>0.240692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010855</td>\n",
       "      <td>-0.031383</td>\n",
       "      <td>0.130922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.015157</td>\n",
       "      <td>-0.057507</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.019821</td>\n",
       "      <td>0.016979</td>\n",
       "      <td>0.027614</td>\n",
       "      <td>0.004063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentageLeft</th>\n",
       "      <td>0.014055</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>-0.016962</td>\n",
       "      <td>0.008117</td>\n",
       "      <td>-0.053117</td>\n",
       "      <td>-0.009636</td>\n",
       "      <td>0.010855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007668</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>-0.024069</td>\n",
       "      <td>0.018664</td>\n",
       "      <td>-0.000591</td>\n",
       "      <td>-0.011363</td>\n",
       "      <td>-0.009842</td>\n",
       "      <td>-0.015377</td>\n",
       "      <td>-0.006644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platform</th>\n",
       "      <td>-0.031564</td>\n",
       "      <td>-0.162144</td>\n",
       "      <td>0.192754</td>\n",
       "      <td>0.010827</td>\n",
       "      <td>-0.043799</td>\n",
       "      <td>0.077311</td>\n",
       "      <td>-0.031383</td>\n",
       "      <td>-0.007668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.039765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019643</td>\n",
       "      <td>-0.008080</td>\n",
       "      <td>-0.079170</td>\n",
       "      <td>0.043194</td>\n",
       "      <td>-0.020286</td>\n",
       "      <td>-0.042101</td>\n",
       "      <td>-0.105236</td>\n",
       "      <td>0.193477</td>\n",
       "      <td>-0.030746</td>\n",
       "      <td>0.057036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playTime</th>\n",
       "      <td>0.009165</td>\n",
       "      <td>-0.008135</td>\n",
       "      <td>0.119006</td>\n",
       "      <td>0.037795</td>\n",
       "      <td>0.038585</td>\n",
       "      <td>0.222778</td>\n",
       "      <td>0.130922</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>-0.039765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003141</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>-0.011453</td>\n",
       "      <td>-0.040716</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>-0.026308</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>-0.013653</td>\n",
       "      <td>0.042872</td>\n",
       "      <td>-0.009883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sessions</th>\n",
       "      <td>0.017118</td>\n",
       "      <td>-0.046011</td>\n",
       "      <td>0.825780</td>\n",
       "      <td>0.252998</td>\n",
       "      <td>-0.271846</td>\n",
       "      <td>0.807976</td>\n",
       "      <td>0.213559</td>\n",
       "      <td>-0.014577</td>\n",
       "      <td>0.105921</td>\n",
       "      <td>0.161857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023612</td>\n",
       "      <td>0.097735</td>\n",
       "      <td>-0.065405</td>\n",
       "      <td>-0.008861</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>-0.033244</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.062086</td>\n",
       "      <td>-0.013833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twentileLeft</th>\n",
       "      <td>0.014931</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>-0.017633</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>-0.055236</td>\n",
       "      <td>-0.007071</td>\n",
       "      <td>0.013357</td>\n",
       "      <td>0.904155</td>\n",
       "      <td>-0.011668</td>\n",
       "      <td>0.024609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002187</td>\n",
       "      <td>-0.001272</td>\n",
       "      <td>0.013648</td>\n",
       "      <td>-0.024316</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>-0.005913</td>\n",
       "      <td>-0.008119</td>\n",
       "      <td>-0.003233</td>\n",
       "      <td>-0.015668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.016421</td>\n",
       "      <td>0.325853</td>\n",
       "      <td>-0.006095</td>\n",
       "      <td>0.169333</td>\n",
       "      <td>-0.012764</td>\n",
       "      <td>0.064359</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>-0.042940</td>\n",
       "      <td>-0.032615</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012425</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>-0.021407</td>\n",
       "      <td>-0.011487</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>-0.004576</td>\n",
       "      <td>-0.011765</td>\n",
       "      <td>0.039558</td>\n",
       "      <td>-0.005909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002075</td>\n",
       "      <td>-0.003707</td>\n",
       "      <td>-0.056919</td>\n",
       "      <td>0.031477</td>\n",
       "      <td>-0.007572</td>\n",
       "      <td>-0.015977</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.013775</td>\n",
       "      <td>-0.005230</td>\n",
       "      <td>-0.021709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022368</td>\n",
       "      <td>0.004352</td>\n",
       "      <td>-0.011501</td>\n",
       "      <td>-0.038822</td>\n",
       "      <td>0.022930</td>\n",
       "      <td>-0.009123</td>\n",
       "      <td>-0.021502</td>\n",
       "      <td>0.015703</td>\n",
       "      <td>0.009649</td>\n",
       "      <td>0.025857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.012933</td>\n",
       "      <td>-0.022281</td>\n",
       "      <td>0.126367</td>\n",
       "      <td>-0.006683</td>\n",
       "      <td>-0.013788</td>\n",
       "      <td>0.052338</td>\n",
       "      <td>-0.016719</td>\n",
       "      <td>-0.006215</td>\n",
       "      <td>0.041217</td>\n",
       "      <td>-0.005913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028789</td>\n",
       "      <td>0.012056</td>\n",
       "      <td>-0.019366</td>\n",
       "      <td>0.033791</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>-0.003719</td>\n",
       "      <td>0.009230</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.002667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.015643</td>\n",
       "      <td>0.027086</td>\n",
       "      <td>-0.073916</td>\n",
       "      <td>-0.025200</td>\n",
       "      <td>0.022159</td>\n",
       "      <td>-0.038383</td>\n",
       "      <td>0.004324</td>\n",
       "      <td>-0.007588</td>\n",
       "      <td>-0.037745</td>\n",
       "      <td>0.028381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007226</td>\n",
       "      <td>-0.017055</td>\n",
       "      <td>0.032009</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>-0.028090</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.025876</td>\n",
       "      <td>-0.025707</td>\n",
       "      <td>-0.010056</td>\n",
       "      <td>-0.029229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w0</th>\n",
       "      <td>-0.020940</td>\n",
       "      <td>-0.056644</td>\n",
       "      <td>0.459980</td>\n",
       "      <td>0.026881</td>\n",
       "      <td>-0.019509</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.015163</td>\n",
       "      <td>-0.015507</td>\n",
       "      <td>0.186719</td>\n",
       "      <td>-0.017779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009077</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>-0.027824</td>\n",
       "      <td>0.017632</td>\n",
       "      <td>0.058514</td>\n",
       "      <td>0.050241</td>\n",
       "      <td>-0.037059</td>\n",
       "      <td>0.038780</td>\n",
       "      <td>-0.063148</td>\n",
       "      <td>0.038759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w10</th>\n",
       "      <td>0.007958</td>\n",
       "      <td>-0.006169</td>\n",
       "      <td>0.276765</td>\n",
       "      <td>0.034525</td>\n",
       "      <td>-0.100855</td>\n",
       "      <td>0.137450</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.038330</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006217</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.017442</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>0.011043</td>\n",
       "      <td>-0.028991</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>-0.041462</td>\n",
       "      <td>0.065795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w20</th>\n",
       "      <td>0.010397</td>\n",
       "      <td>-0.023979</td>\n",
       "      <td>0.231551</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>-0.039374</td>\n",
       "      <td>0.077064</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>-0.001239</td>\n",
       "      <td>0.048704</td>\n",
       "      <td>0.024365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005675</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>-0.006821</td>\n",
       "      <td>-0.006545</td>\n",
       "      <td>-0.023132</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>-0.010374</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>0.012229</td>\n",
       "      <td>-0.010002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w30</th>\n",
       "      <td>-0.001786</td>\n",
       "      <td>-0.019654</td>\n",
       "      <td>0.247360</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>-0.067307</td>\n",
       "      <td>0.094804</td>\n",
       "      <td>0.024573</td>\n",
       "      <td>-0.020531</td>\n",
       "      <td>0.035171</td>\n",
       "      <td>-0.012568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006730</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>0.012592</td>\n",
       "      <td>0.004289</td>\n",
       "      <td>-0.024513</td>\n",
       "      <td>-0.012480</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>-0.011861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w40</th>\n",
       "      <td>0.015148</td>\n",
       "      <td>-0.027739</td>\n",
       "      <td>0.227289</td>\n",
       "      <td>0.050688</td>\n",
       "      <td>-0.056056</td>\n",
       "      <td>0.188478</td>\n",
       "      <td>0.050307</td>\n",
       "      <td>-0.013596</td>\n",
       "      <td>0.047365</td>\n",
       "      <td>0.029439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081844</td>\n",
       "      <td>-0.002740</td>\n",
       "      <td>-0.107450</td>\n",
       "      <td>-0.014984</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>-0.004147</td>\n",
       "      <td>0.054878</td>\n",
       "      <td>0.090957</td>\n",
       "      <td>-0.012615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w50</th>\n",
       "      <td>0.017102</td>\n",
       "      <td>-0.014646</td>\n",
       "      <td>0.262228</td>\n",
       "      <td>0.092440</td>\n",
       "      <td>-0.107018</td>\n",
       "      <td>0.312373</td>\n",
       "      <td>0.116225</td>\n",
       "      <td>0.011615</td>\n",
       "      <td>-0.001879</td>\n",
       "      <td>0.114769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007062</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>-0.034051</td>\n",
       "      <td>-0.031199</td>\n",
       "      <td>-0.064098</td>\n",
       "      <td>0.019208</td>\n",
       "      <td>-0.014855</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>-0.013235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w60</th>\n",
       "      <td>-0.017055</td>\n",
       "      <td>0.074031</td>\n",
       "      <td>-0.868037</td>\n",
       "      <td>-0.138264</td>\n",
       "      <td>0.212054</td>\n",
       "      <td>-0.584145</td>\n",
       "      <td>-0.152316</td>\n",
       "      <td>0.011843</td>\n",
       "      <td>-0.163154</td>\n",
       "      <td>-0.113408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016810</td>\n",
       "      <td>-0.045815</td>\n",
       "      <td>0.037189</td>\n",
       "      <td>0.020716</td>\n",
       "      <td>-0.001211</td>\n",
       "      <td>0.021394</td>\n",
       "      <td>0.028230</td>\n",
       "      <td>-0.038133</td>\n",
       "      <td>-0.020668</td>\n",
       "      <td>-0.019480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casual_mode</th>\n",
       "      <td>0.016725</td>\n",
       "      <td>-0.031279</td>\n",
       "      <td>0.709277</td>\n",
       "      <td>0.403199</td>\n",
       "      <td>-0.237050</td>\n",
       "      <td>0.903370</td>\n",
       "      <td>0.186222</td>\n",
       "      <td>-0.022021</td>\n",
       "      <td>0.080108</td>\n",
       "      <td>0.149950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019587</td>\n",
       "      <td>0.075597</td>\n",
       "      <td>-0.056912</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>-0.016513</td>\n",
       "      <td>0.012423</td>\n",
       "      <td>-0.029890</td>\n",
       "      <td>-0.025052</td>\n",
       "      <td>0.084917</td>\n",
       "      <td>-0.010015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alternative_mode</th>\n",
       "      <td>0.012534</td>\n",
       "      <td>-0.020726</td>\n",
       "      <td>0.634605</td>\n",
       "      <td>0.306628</td>\n",
       "      <td>-0.474141</td>\n",
       "      <td>0.716852</td>\n",
       "      <td>0.161851</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.070730</td>\n",
       "      <td>0.070794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030409</td>\n",
       "      <td>0.065007</td>\n",
       "      <td>-0.052062</td>\n",
       "      <td>0.033419</td>\n",
       "      <td>-0.004295</td>\n",
       "      <td>-0.002204</td>\n",
       "      <td>-0.019990</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.048286</td>\n",
       "      <td>-0.000996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_mode</th>\n",
       "      <td>0.025454</td>\n",
       "      <td>-0.024664</td>\n",
       "      <td>0.483912</td>\n",
       "      <td>0.125628</td>\n",
       "      <td>-0.180017</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.085073</td>\n",
       "      <td>-0.006285</td>\n",
       "      <td>0.041843</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040445</td>\n",
       "      <td>0.040315</td>\n",
       "      <td>-0.056367</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>-0.015316</td>\n",
       "      <td>0.017118</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.013449</td>\n",
       "      <td>0.044740</td>\n",
       "      <td>-0.023358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoosterUsed</th>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.009265</td>\n",
       "      <td>-0.059787</td>\n",
       "      <td>-0.038825</td>\n",
       "      <td>0.012765</td>\n",
       "      <td>-0.056810</td>\n",
       "      <td>-0.007720</td>\n",
       "      <td>0.179280</td>\n",
       "      <td>-0.025231</td>\n",
       "      <td>-0.011285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003806</td>\n",
       "      <td>-0.016379</td>\n",
       "      <td>0.016618</td>\n",
       "      <td>-0.014334</td>\n",
       "      <td>0.010911</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.017629</td>\n",
       "      <td>-0.019030</td>\n",
       "      <td>-0.009662</td>\n",
       "      <td>0.008604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LevelTime</th>\n",
       "      <td>0.007786</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>-0.056874</td>\n",
       "      <td>-0.062470</td>\n",
       "      <td>-0.022973</td>\n",
       "      <td>-0.040462</td>\n",
       "      <td>-0.037862</td>\n",
       "      <td>0.477866</td>\n",
       "      <td>-0.013504</td>\n",
       "      <td>0.214636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009962</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.009220</td>\n",
       "      <td>-0.019540</td>\n",
       "      <td>-0.003618</td>\n",
       "      <td>-0.018529</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.007721</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>-0.004892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentage</th>\n",
       "      <td>-0.011111</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>0.076426</td>\n",
       "      <td>0.073547</td>\n",
       "      <td>0.016570</td>\n",
       "      <td>0.059903</td>\n",
       "      <td>0.038451</td>\n",
       "      <td>-0.517004</td>\n",
       "      <td>0.022421</td>\n",
       "      <td>-0.196650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010804</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>-0.015072</td>\n",
       "      <td>0.023854</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>0.014570</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.014603</td>\n",
       "      <td>-0.008819</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD</th>\n",
       "      <td>0.013775</td>\n",
       "      <td>-0.005094</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>-0.011841</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>-0.006730</td>\n",
       "      <td>-0.013436</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>-0.001374</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>0.083920</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>-0.001489</td>\n",
       "      <td>-0.004352</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>-0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RO</th>\n",
       "      <td>0.011609</td>\n",
       "      <td>0.043912</td>\n",
       "      <td>-0.031462</td>\n",
       "      <td>-0.011514</td>\n",
       "      <td>-0.004368</td>\n",
       "      <td>-0.007197</td>\n",
       "      <td>-0.004595</td>\n",
       "      <td>-0.007041</td>\n",
       "      <td>-0.004569</td>\n",
       "      <td>0.041862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002218</td>\n",
       "      <td>-0.009545</td>\n",
       "      <td>0.057894</td>\n",
       "      <td>-0.008354</td>\n",
       "      <td>-0.011812</td>\n",
       "      <td>-0.013954</td>\n",
       "      <td>-0.010343</td>\n",
       "      <td>-0.022251</td>\n",
       "      <td>-0.031960</td>\n",
       "      <td>-0.003909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.018035</td>\n",
       "      <td>-0.020082</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>0.010123</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.025061</td>\n",
       "      <td>-0.021841</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>-0.003368</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>-0.002947</td>\n",
       "      <td>-0.004167</td>\n",
       "      <td>-0.004923</td>\n",
       "      <td>-0.003649</td>\n",
       "      <td>-0.010662</td>\n",
       "      <td>-0.011275</td>\n",
       "      <td>-0.001379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RU</th>\n",
       "      <td>-0.004531</td>\n",
       "      <td>-0.024135</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>-0.020534</td>\n",
       "      <td>-0.022661</td>\n",
       "      <td>-0.019110</td>\n",
       "      <td>-0.011538</td>\n",
       "      <td>-0.002757</td>\n",
       "      <td>0.181621</td>\n",
       "      <td>-0.007132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011274</td>\n",
       "      <td>-0.048520</td>\n",
       "      <td>-0.376081</td>\n",
       "      <td>-0.039749</td>\n",
       "      <td>-0.060041</td>\n",
       "      <td>-0.067599</td>\n",
       "      <td>-0.052574</td>\n",
       "      <td>0.799535</td>\n",
       "      <td>-0.162453</td>\n",
       "      <td>-0.019871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SA</th>\n",
       "      <td>0.004418</td>\n",
       "      <td>-0.022395</td>\n",
       "      <td>0.052777</td>\n",
       "      <td>-0.053351</td>\n",
       "      <td>-0.040694</td>\n",
       "      <td>-0.005780</td>\n",
       "      <td>0.022497</td>\n",
       "      <td>0.024230</td>\n",
       "      <td>0.039417</td>\n",
       "      <td>-0.016153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009713</td>\n",
       "      <td>-0.017595</td>\n",
       "      <td>0.241380</td>\n",
       "      <td>-0.036583</td>\n",
       "      <td>-0.038559</td>\n",
       "      <td>-0.051718</td>\n",
       "      <td>-0.017902</td>\n",
       "      <td>-0.127397</td>\n",
       "      <td>-0.124693</td>\n",
       "      <td>-0.017119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.000604</td>\n",
       "      <td>-0.005094</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>-0.024433</td>\n",
       "      <td>-0.004759</td>\n",
       "      <td>-0.001260</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>-0.001374</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>-0.001489</td>\n",
       "      <td>-0.004352</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>-0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SE</th>\n",
       "      <td>-0.010183</td>\n",
       "      <td>0.019290</td>\n",
       "      <td>-0.032416</td>\n",
       "      <td>-0.009965</td>\n",
       "      <td>-0.018088</td>\n",
       "      <td>-0.042472</td>\n",
       "      <td>-0.019948</td>\n",
       "      <td>-0.006742</td>\n",
       "      <td>0.021213</td>\n",
       "      <td>-0.003609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001920</td>\n",
       "      <td>-0.008262</td>\n",
       "      <td>0.055161</td>\n",
       "      <td>-0.007230</td>\n",
       "      <td>-0.010223</td>\n",
       "      <td>-0.012078</td>\n",
       "      <td>-0.008952</td>\n",
       "      <td>-0.026157</td>\n",
       "      <td>-0.027661</td>\n",
       "      <td>-0.003383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SG</th>\n",
       "      <td>-0.016391</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>-0.000533</td>\n",
       "      <td>0.017053</td>\n",
       "      <td>0.008265</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>-0.003587</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.020460</td>\n",
       "      <td>0.010265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000639</td>\n",
       "      <td>-0.002749</td>\n",
       "      <td>0.018357</td>\n",
       "      <td>-0.002406</td>\n",
       "      <td>-0.003402</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>-0.008705</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>-0.001126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SK</th>\n",
       "      <td>0.022131</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>-0.015430</td>\n",
       "      <td>0.019067</td>\n",
       "      <td>0.009241</td>\n",
       "      <td>-0.015093</td>\n",
       "      <td>-0.009970</td>\n",
       "      <td>-0.021746</td>\n",
       "      <td>0.004896</td>\n",
       "      <td>-0.003338</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.003074</td>\n",
       "      <td>-0.006551</td>\n",
       "      <td>-0.002690</td>\n",
       "      <td>-0.003804</td>\n",
       "      <td>-0.004494</td>\n",
       "      <td>-0.003331</td>\n",
       "      <td>0.027235</td>\n",
       "      <td>-0.010292</td>\n",
       "      <td>-0.001259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SY</th>\n",
       "      <td>0.055351</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.012294</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>-0.009289</td>\n",
       "      <td>-0.013135</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>-0.015993</td>\n",
       "      <td>0.007548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002418</td>\n",
       "      <td>-0.010407</td>\n",
       "      <td>0.069483</td>\n",
       "      <td>-0.009108</td>\n",
       "      <td>-0.012878</td>\n",
       "      <td>-0.015213</td>\n",
       "      <td>-0.011276</td>\n",
       "      <td>-0.032949</td>\n",
       "      <td>-0.034843</td>\n",
       "      <td>-0.004262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TH</th>\n",
       "      <td>-0.044212</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.019427</td>\n",
       "      <td>0.049798</td>\n",
       "      <td>0.017521</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.015344</td>\n",
       "      <td>0.007213</td>\n",
       "      <td>0.029666</td>\n",
       "      <td>-0.002265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003009</td>\n",
       "      <td>-0.012951</td>\n",
       "      <td>0.062706</td>\n",
       "      <td>-0.011334</td>\n",
       "      <td>0.016659</td>\n",
       "      <td>-0.018933</td>\n",
       "      <td>-0.014033</td>\n",
       "      <td>-0.023306</td>\n",
       "      <td>-0.043361</td>\n",
       "      <td>-0.005304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TJ</th>\n",
       "      <td>0.014833</td>\n",
       "      <td>-0.005094</td>\n",
       "      <td>0.011249</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>-0.015980</td>\n",
       "      <td>-0.001260</td>\n",
       "      <td>-0.013129</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>-0.006611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>0.073445</td>\n",
       "      <td>-0.011000</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>-0.001489</td>\n",
       "      <td>-0.004352</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>-0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TM</th>\n",
       "      <td>0.068907</td>\n",
       "      <td>-0.036472</td>\n",
       "      <td>-0.068770</td>\n",
       "      <td>-0.076200</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>-0.079973</td>\n",
       "      <td>0.088053</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.047838</td>\n",
       "      <td>-0.060569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002287</td>\n",
       "      <td>-0.009841</td>\n",
       "      <td>-0.078755</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>-0.012177</td>\n",
       "      <td>-0.014386</td>\n",
       "      <td>-0.010663</td>\n",
       "      <td>0.142874</td>\n",
       "      <td>-0.010595</td>\n",
       "      <td>-0.004030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN</th>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.010411</td>\n",
       "      <td>-0.011592</td>\n",
       "      <td>0.012057</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>-0.003648</td>\n",
       "      <td>-0.013972</td>\n",
       "      <td>-0.004640</td>\n",
       "      <td>-0.013958</td>\n",
       "      <td>0.014714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000452</td>\n",
       "      <td>-0.001944</td>\n",
       "      <td>-0.015557</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>0.083940</td>\n",
       "      <td>-0.002842</td>\n",
       "      <td>-0.002106</td>\n",
       "      <td>-0.006155</td>\n",
       "      <td>-0.006509</td>\n",
       "      <td>-0.000796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TR</th>\n",
       "      <td>0.017165</td>\n",
       "      <td>0.041401</td>\n",
       "      <td>-0.003048</td>\n",
       "      <td>0.040734</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.067163</td>\n",
       "      <td>0.021057</td>\n",
       "      <td>-0.013865</td>\n",
       "      <td>-0.023845</td>\n",
       "      <td>0.044523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014677</td>\n",
       "      <td>-0.059216</td>\n",
       "      <td>-0.464507</td>\n",
       "      <td>-0.053034</td>\n",
       "      <td>-0.058826</td>\n",
       "      <td>-0.092343</td>\n",
       "      <td>-0.068444</td>\n",
       "      <td>-0.191995</td>\n",
       "      <td>0.935936</td>\n",
       "      <td>-0.025869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TW</th>\n",
       "      <td>-0.026073</td>\n",
       "      <td>0.013039</td>\n",
       "      <td>-0.010405</td>\n",
       "      <td>0.018305</td>\n",
       "      <td>0.024132</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>-0.020166</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>0.032121</td>\n",
       "      <td>0.031944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001865</td>\n",
       "      <td>-0.008028</td>\n",
       "      <td>0.046669</td>\n",
       "      <td>-0.007026</td>\n",
       "      <td>-0.009934</td>\n",
       "      <td>-0.011736</td>\n",
       "      <td>-0.008699</td>\n",
       "      <td>-0.025418</td>\n",
       "      <td>-0.026879</td>\n",
       "      <td>0.058519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UA</th>\n",
       "      <td>-0.014077</td>\n",
       "      <td>-0.001360</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.019927</td>\n",
       "      <td>-0.002453</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>-0.011388</td>\n",
       "      <td>-0.011028</td>\n",
       "      <td>0.013106</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003874</td>\n",
       "      <td>-0.016673</td>\n",
       "      <td>-0.104736</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>-0.020632</td>\n",
       "      <td>-0.024374</td>\n",
       "      <td>-0.018066</td>\n",
       "      <td>0.237592</td>\n",
       "      <td>-0.055823</td>\n",
       "      <td>-0.006828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>US</th>\n",
       "      <td>0.012545</td>\n",
       "      <td>-0.003194</td>\n",
       "      <td>0.061447</td>\n",
       "      <td>0.014522</td>\n",
       "      <td>-0.039253</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>-0.028575</td>\n",
       "      <td>0.018065</td>\n",
       "      <td>0.144290</td>\n",
       "      <td>-0.010197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005937</td>\n",
       "      <td>-0.021388</td>\n",
       "      <td>0.153765</td>\n",
       "      <td>0.025017</td>\n",
       "      <td>-0.028222</td>\n",
       "      <td>-0.037356</td>\n",
       "      <td>-0.027688</td>\n",
       "      <td>-0.076304</td>\n",
       "      <td>-0.085555</td>\n",
       "      <td>-0.010465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UZ</th>\n",
       "      <td>-0.046401</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.022935</td>\n",
       "      <td>-0.038390</td>\n",
       "      <td>-0.020556</td>\n",
       "      <td>0.025288</td>\n",
       "      <td>-0.014296</td>\n",
       "      <td>-0.034668</td>\n",
       "      <td>0.011047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001893</td>\n",
       "      <td>-0.008146</td>\n",
       "      <td>-0.065189</td>\n",
       "      <td>-0.007129</td>\n",
       "      <td>-0.010080</td>\n",
       "      <td>-0.011908</td>\n",
       "      <td>-0.008826</td>\n",
       "      <td>0.137470</td>\n",
       "      <td>-0.027273</td>\n",
       "      <td>-0.003336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VN</th>\n",
       "      <td>-0.113400</td>\n",
       "      <td>-0.016272</td>\n",
       "      <td>-0.090873</td>\n",
       "      <td>0.068689</td>\n",
       "      <td>0.025189</td>\n",
       "      <td>-0.008726</td>\n",
       "      <td>-0.031520</td>\n",
       "      <td>0.011586</td>\n",
       "      <td>0.028951</td>\n",
       "      <td>0.014391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005341</td>\n",
       "      <td>-0.004586</td>\n",
       "      <td>0.148506</td>\n",
       "      <td>-0.020116</td>\n",
       "      <td>-0.028443</td>\n",
       "      <td>-0.033602</td>\n",
       "      <td>-0.024906</td>\n",
       "      <td>-0.072775</td>\n",
       "      <td>-0.076958</td>\n",
       "      <td>-0.009413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YE</th>\n",
       "      <td>0.014495</td>\n",
       "      <td>-0.005094</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>0.008525</td>\n",
       "      <td>-0.024433</td>\n",
       "      <td>0.013807</td>\n",
       "      <td>-0.013436</td>\n",
       "      <td>0.006315</td>\n",
       "      <td>-0.009869</td>\n",
       "      <td>-0.005367</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>-0.001374</td>\n",
       "      <td>0.009177</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>-0.001701</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>-0.001489</td>\n",
       "      <td>-0.004352</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>-0.000563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZA</th>\n",
       "      <td>0.024028</td>\n",
       "      <td>-0.016117</td>\n",
       "      <td>0.022902</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>-0.023076</td>\n",
       "      <td>0.025313</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.019643</td>\n",
       "      <td>-0.003141</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.004348</td>\n",
       "      <td>0.029034</td>\n",
       "      <td>-0.003806</td>\n",
       "      <td>-0.005381</td>\n",
       "      <td>-0.006357</td>\n",
       "      <td>-0.004712</td>\n",
       "      <td>-0.013768</td>\n",
       "      <td>-0.014559</td>\n",
       "      <td>-0.001781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>-0.017764</td>\n",
       "      <td>0.010773</td>\n",
       "      <td>0.065366</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>-0.037770</td>\n",
       "      <td>0.068390</td>\n",
       "      <td>0.015157</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.008080</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.149773</td>\n",
       "      <td>-0.016379</td>\n",
       "      <td>-0.023158</td>\n",
       "      <td>-0.027359</td>\n",
       "      <td>-0.020278</td>\n",
       "      <td>-0.059253</td>\n",
       "      <td>-0.062660</td>\n",
       "      <td>-0.007664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>-0.022509</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>-0.041482</td>\n",
       "      <td>-0.002128</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>-0.055050</td>\n",
       "      <td>-0.057507</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>-0.079170</td>\n",
       "      <td>-0.011453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029034</td>\n",
       "      <td>-0.149773</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131077</td>\n",
       "      <td>-0.185336</td>\n",
       "      <td>-0.218952</td>\n",
       "      <td>-0.162286</td>\n",
       "      <td>-0.474202</td>\n",
       "      <td>-0.501462</td>\n",
       "      <td>-0.061338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>-0.023532</td>\n",
       "      <td>-0.028424</td>\n",
       "      <td>0.012765</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>-0.024069</td>\n",
       "      <td>0.043194</td>\n",
       "      <td>-0.040716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003806</td>\n",
       "      <td>-0.016379</td>\n",
       "      <td>-0.131077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020268</td>\n",
       "      <td>-0.023944</td>\n",
       "      <td>-0.017747</td>\n",
       "      <td>-0.051857</td>\n",
       "      <td>-0.054838</td>\n",
       "      <td>-0.006708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fr</th>\n",
       "      <td>0.042495</td>\n",
       "      <td>-0.017401</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>-0.034151</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>-0.019599</td>\n",
       "      <td>0.019830</td>\n",
       "      <td>0.018664</td>\n",
       "      <td>-0.020286</td>\n",
       "      <td>0.024714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005381</td>\n",
       "      <td>-0.023158</td>\n",
       "      <td>-0.185336</td>\n",
       "      <td>-0.020268</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033855</td>\n",
       "      <td>-0.025093</td>\n",
       "      <td>-0.073323</td>\n",
       "      <td>-0.077538</td>\n",
       "      <td>-0.009484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>-0.000975</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.038964</td>\n",
       "      <td>0.022720</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>-0.000591</td>\n",
       "      <td>-0.042101</td>\n",
       "      <td>-0.026308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006357</td>\n",
       "      <td>-0.027359</td>\n",
       "      <td>-0.218952</td>\n",
       "      <td>-0.023944</td>\n",
       "      <td>-0.033855</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029645</td>\n",
       "      <td>-0.086622</td>\n",
       "      <td>-0.091602</td>\n",
       "      <td>-0.011205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt-BR</th>\n",
       "      <td>-0.024485</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>-0.044980</td>\n",
       "      <td>-0.016702</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>-0.022659</td>\n",
       "      <td>0.019821</td>\n",
       "      <td>-0.011363</td>\n",
       "      <td>-0.105236</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004712</td>\n",
       "      <td>-0.020278</td>\n",
       "      <td>-0.162286</td>\n",
       "      <td>-0.017747</td>\n",
       "      <td>-0.025093</td>\n",
       "      <td>-0.029645</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.064204</td>\n",
       "      <td>-0.067894</td>\n",
       "      <td>-0.008305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ru</th>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.037771</td>\n",
       "      <td>0.034922</td>\n",
       "      <td>-0.027435</td>\n",
       "      <td>-0.021740</td>\n",
       "      <td>-0.025153</td>\n",
       "      <td>0.016979</td>\n",
       "      <td>-0.009842</td>\n",
       "      <td>0.193477</td>\n",
       "      <td>-0.013653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013768</td>\n",
       "      <td>-0.059253</td>\n",
       "      <td>-0.474202</td>\n",
       "      <td>-0.051857</td>\n",
       "      <td>-0.073323</td>\n",
       "      <td>-0.086622</td>\n",
       "      <td>-0.064204</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.198389</td>\n",
       "      <td>-0.024267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tr</th>\n",
       "      <td>0.014889</td>\n",
       "      <td>0.036795</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>0.051418</td>\n",
       "      <td>-0.006442</td>\n",
       "      <td>0.078044</td>\n",
       "      <td>0.027614</td>\n",
       "      <td>-0.015377</td>\n",
       "      <td>-0.030746</td>\n",
       "      <td>0.042872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014559</td>\n",
       "      <td>-0.062660</td>\n",
       "      <td>-0.501462</td>\n",
       "      <td>-0.054838</td>\n",
       "      <td>-0.077538</td>\n",
       "      <td>-0.091602</td>\n",
       "      <td>-0.067894</td>\n",
       "      <td>-0.198389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zh-CN</th>\n",
       "      <td>0.007735</td>\n",
       "      <td>-0.023926</td>\n",
       "      <td>0.027481</td>\n",
       "      <td>0.032885</td>\n",
       "      <td>0.023039</td>\n",
       "      <td>-0.004977</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>-0.006644</td>\n",
       "      <td>0.057036</td>\n",
       "      <td>-0.009883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001781</td>\n",
       "      <td>-0.007664</td>\n",
       "      <td>-0.061338</td>\n",
       "      <td>-0.006708</td>\n",
       "      <td>-0.009484</td>\n",
       "      <td>-0.011205</td>\n",
       "      <td>-0.008305</td>\n",
       "      <td>-0.024267</td>\n",
       "      <td>-0.025662</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Unnamed: 0  adOption  daysSinceInstall  hasEnoughCoin  \\\n",
       "Unnamed: 0          1.000000 -0.001869          0.007306      -0.020841   \n",
       "adOption           -0.001869  1.000000         -0.082626       0.005615   \n",
       "daysSinceInstall    0.007306 -0.082626          1.000000       0.159088   \n",
       "hasEnoughCoin      -0.020841  0.005615          0.159088       1.000000   \n",
       "levelMode           0.002573  0.009286         -0.225098      -0.155804   \n",
       "levelNumber         0.020190 -0.021917          0.632715       0.411498   \n",
       "numFails            0.016578 -0.022779          0.153595       0.006241   \n",
       "percentageLeft      0.014055  0.003613         -0.016962       0.008117   \n",
       "platform           -0.031564 -0.162144          0.192754       0.010827   \n",
       "playTime            0.009165 -0.008135          0.119006       0.037795   \n",
       "sessions            0.017118 -0.046011          0.825780       0.252998   \n",
       "twentileLeft        0.014931  0.000854         -0.017633       0.003226   \n",
       "target              0.016421  0.325853         -0.006095       0.169333   \n",
       "4                  -0.002075 -0.003707         -0.056919       0.031477   \n",
       "5                  -0.012933 -0.022281          0.126367      -0.006683   \n",
       "6                   0.015643  0.027086         -0.073916      -0.025200   \n",
       "w0                 -0.020940 -0.056644          0.459980       0.026881   \n",
       "w10                 0.007958 -0.006169          0.276765       0.034525   \n",
       "w20                 0.010397 -0.023979          0.231551       0.009567   \n",
       "w30                -0.001786 -0.019654          0.247360       0.001921   \n",
       "w40                 0.015148 -0.027739          0.227289       0.050688   \n",
       "w50                 0.017102 -0.014646          0.262228       0.092440   \n",
       "w60                -0.017055  0.074031         -0.868037      -0.138264   \n",
       "casual_mode         0.016725 -0.031279          0.709277       0.403199   \n",
       "alternative_mode    0.012534 -0.020726          0.634605       0.306628   \n",
       "event_mode          0.025454 -0.024664          0.483912       0.125628   \n",
       "BoosterUsed         0.009859  0.009265         -0.059787      -0.038825   \n",
       "LevelTime           0.007786 -0.003673         -0.056874      -0.062470   \n",
       "Percentage         -0.011111 -0.000149          0.076426       0.073547   \n",
       "AD                  0.013775 -0.005094          0.005146      -0.011841   \n",
       "...                      ...       ...               ...            ...   \n",
       "RO                  0.011609  0.043912         -0.031462      -0.011514   \n",
       "RS                  0.014545  0.018035         -0.020082       0.020888   \n",
       "RU                 -0.004531 -0.024135          0.033036      -0.020534   \n",
       "SA                  0.004418 -0.022395          0.052777      -0.053351   \n",
       "SD                  0.000604 -0.005094         -0.001710       0.008525   \n",
       "SE                 -0.010183  0.019290         -0.032416      -0.009965   \n",
       "SG                 -0.016391  0.002267         -0.000533       0.017053   \n",
       "SK                  0.022131 -0.011393         -0.015430       0.019067   \n",
       "SY                  0.055351  0.004445          0.012294       0.002326   \n",
       "TH                 -0.044212  0.000010          0.019427       0.049798   \n",
       "TJ                  0.014833 -0.005094          0.011249       0.008525   \n",
       "TM                  0.068907 -0.036472         -0.068770      -0.076200   \n",
       "TN                  0.000576  0.010411         -0.011592       0.012057   \n",
       "TR                  0.017165  0.041401         -0.003048       0.040734   \n",
       "TW                 -0.026073  0.013039         -0.010405       0.018305   \n",
       "UA                 -0.014077 -0.001360          0.007654       0.019927   \n",
       "US                  0.012545 -0.003194          0.061447       0.014522   \n",
       "UZ                 -0.046401  0.003553          0.019470       0.022935   \n",
       "VN                 -0.113400 -0.016272         -0.090873       0.068689   \n",
       "YE                  0.014495 -0.005094          0.010150       0.008525   \n",
       "ZA                  0.024028 -0.016117          0.022902       0.014085   \n",
       "de                 -0.017764  0.010773          0.065366       0.001804   \n",
       "en                 -0.022509 -0.000259         -0.041482      -0.002128   \n",
       "es                  0.000947  0.002904         -0.023532      -0.028424   \n",
       "fr                  0.042495 -0.017401          0.016796      -0.034151   \n",
       "it                  0.020833  0.005316         -0.000975       0.004771   \n",
       "pt-BR              -0.024485  0.009388         -0.044980      -0.016702   \n",
       "ru                 -0.000096 -0.037771          0.034922      -0.027435   \n",
       "tr                  0.014889  0.036795          0.011442       0.051418   \n",
       "zh-CN               0.007735 -0.023926          0.027481       0.032885   \n",
       "\n",
       "                  levelMode  levelNumber  numFails  percentageLeft  platform  \\\n",
       "Unnamed: 0         0.002573     0.020190  0.016578        0.014055 -0.031564   \n",
       "adOption           0.009286    -0.021917 -0.022779        0.003613 -0.162144   \n",
       "daysSinceInstall  -0.225098     0.632715  0.153595       -0.016962  0.192754   \n",
       "hasEnoughCoin     -0.155804     0.411498  0.006241        0.008117  0.010827   \n",
       "levelMode          1.000000    -0.180247 -0.013784       -0.053117 -0.043799   \n",
       "levelNumber       -0.180247     1.000000  0.240692       -0.009636  0.077311   \n",
       "numFails          -0.013784     0.240692  1.000000        0.010855 -0.031383   \n",
       "percentageLeft    -0.053117    -0.009636  0.010855        1.000000 -0.007668   \n",
       "platform          -0.043799     0.077311 -0.031383       -0.007668  1.000000   \n",
       "playTime           0.038585     0.222778  0.130922        0.006382 -0.039765   \n",
       "sessions          -0.271846     0.807976  0.213559       -0.014577  0.105921   \n",
       "twentileLeft      -0.055236    -0.007071  0.013357        0.904155 -0.011668   \n",
       "target            -0.012764     0.064359  0.004026       -0.042940 -0.032615   \n",
       "4                 -0.007572    -0.015977  0.012866        0.013775 -0.005230   \n",
       "5                 -0.013788     0.052338 -0.016719       -0.006215  0.041217   \n",
       "6                  0.022159    -0.038383  0.004324       -0.007588 -0.037745   \n",
       "w0                -0.019509     0.185800  0.015163       -0.015507  0.186719   \n",
       "w10               -0.100855     0.137450  0.014152        0.000764  0.038330   \n",
       "w20               -0.039374     0.077064  0.000959       -0.001239  0.048704   \n",
       "w30               -0.067307     0.094804  0.024573       -0.020531  0.035171   \n",
       "w40               -0.056056     0.188478  0.050307       -0.013596  0.047365   \n",
       "w50               -0.107018     0.312373  0.116225        0.011615 -0.001879   \n",
       "w60                0.212054    -0.584145 -0.152316        0.011843 -0.163154   \n",
       "casual_mode       -0.237050     0.903370  0.186222       -0.022021  0.080108   \n",
       "alternative_mode  -0.474141     0.716852  0.161851        0.005501  0.070730   \n",
       "event_mode        -0.180017     0.442396  0.085073       -0.006285  0.041843   \n",
       "BoosterUsed        0.012765    -0.056810 -0.007720        0.179280 -0.025231   \n",
       "LevelTime         -0.022973    -0.040462 -0.037862        0.477866 -0.013504   \n",
       "Percentage         0.016570     0.059903  0.038451       -0.517004  0.022421   \n",
       "AD                 0.004132    -0.006730 -0.013436        0.002551  0.010228   \n",
       "...                     ...          ...       ...             ...       ...   \n",
       "RO                -0.004368    -0.007197 -0.004595       -0.007041 -0.004569   \n",
       "RS                 0.010123     0.020635  0.007273       -0.000017  0.025061   \n",
       "RU                -0.022661    -0.019110 -0.011538       -0.002757  0.181621   \n",
       "SA                -0.040694    -0.005780  0.022497        0.024230  0.039417   \n",
       "SD                -0.024433    -0.004759 -0.001260        0.002551  0.010228   \n",
       "SE                -0.018088    -0.042472 -0.019948       -0.006742  0.021213   \n",
       "SG                 0.008265     0.004415 -0.003587       -0.000093  0.020460   \n",
       "SK                 0.009241    -0.015093 -0.009970       -0.021746  0.004896   \n",
       "SY                 0.019900    -0.009289 -0.013135        0.000561 -0.015993   \n",
       "TH                 0.017521     0.030653  0.015344        0.007213  0.029666   \n",
       "TJ                 0.004132    -0.015980 -0.001260       -0.013129  0.010228   \n",
       "TM                 0.017551    -0.079973  0.088053        0.002483  0.047838   \n",
       "TN                 0.005843    -0.003648 -0.013972       -0.004640 -0.013958   \n",
       "TR                 0.005148     0.067163  0.021057       -0.013865 -0.023845   \n",
       "TW                 0.024132     0.011212 -0.020166       -0.000941  0.032121   \n",
       "UA                -0.002453     0.005350 -0.011388       -0.011028  0.013106   \n",
       "US                -0.039253     0.002784 -0.028575        0.018065  0.144290   \n",
       "UZ                -0.038390    -0.020556  0.025288       -0.014296 -0.034668   \n",
       "VN                 0.025189    -0.008726 -0.031520        0.011586  0.028951   \n",
       "YE                -0.024433     0.013807 -0.013436        0.006315 -0.009869   \n",
       "ZA                -0.023076     0.025313  0.000697        0.001890  0.019643   \n",
       "de                -0.037770     0.068390  0.015157       -0.000304 -0.008080   \n",
       "en                 0.006471    -0.055050 -0.057507        0.022801 -0.079170   \n",
       "es                 0.012765     0.002333  0.025466       -0.024069  0.043194   \n",
       "fr                 0.008583    -0.019599  0.019830        0.018664 -0.020286   \n",
       "it                 0.038964     0.022720  0.003028       -0.000591 -0.042101   \n",
       "pt-BR              0.003580    -0.022659  0.019821       -0.011363 -0.105236   \n",
       "ru                -0.021740    -0.025153  0.016979       -0.009842  0.193477   \n",
       "tr                -0.006442     0.078044  0.027614       -0.015377 -0.030746   \n",
       "zh-CN              0.023039    -0.004977  0.004063       -0.006644  0.057036   \n",
       "\n",
       "                  playTime    ...           ZA        de        en        es  \\\n",
       "Unnamed: 0        0.009165    ...     0.024028 -0.017764 -0.022509  0.000947   \n",
       "adOption         -0.008135    ...    -0.016117  0.010773 -0.000259  0.002904   \n",
       "daysSinceInstall  0.119006    ...     0.022902  0.065366 -0.041482 -0.023532   \n",
       "hasEnoughCoin     0.037795    ...     0.014085  0.001804 -0.002128 -0.028424   \n",
       "levelMode         0.038585    ...    -0.023076 -0.037770  0.006471  0.012765   \n",
       "levelNumber       0.222778    ...     0.025313  0.068390 -0.055050  0.002333   \n",
       "numFails          0.130922    ...     0.000697  0.015157 -0.057507  0.025466   \n",
       "percentageLeft    0.006382    ...     0.001890 -0.000304  0.022801 -0.024069   \n",
       "platform         -0.039765    ...     0.019643 -0.008080 -0.079170  0.043194   \n",
       "playTime          1.000000    ...    -0.003141 -0.003333 -0.011453 -0.040716   \n",
       "sessions          0.161857    ...     0.023612  0.097735 -0.065405 -0.008861   \n",
       "twentileLeft      0.024609    ...    -0.002187 -0.001272  0.013648 -0.024316   \n",
       "target            0.030747    ...    -0.012425  0.013033 -0.021407 -0.011487   \n",
       "4                -0.021709    ...    -0.022368  0.004352 -0.011501 -0.038822   \n",
       "5                -0.005913    ...     0.028789  0.012056 -0.019366  0.033791   \n",
       "6                 0.028381    ...    -0.007226 -0.017055  0.032009  0.004369   \n",
       "w0               -0.017779    ...    -0.009077  0.040643 -0.027824  0.017632   \n",
       "w10               0.003066    ...    -0.006217  0.017137  0.003242  0.017442   \n",
       "w20               0.024365    ...    -0.005675  0.001644 -0.006821 -0.006545   \n",
       "w30              -0.012568    ...    -0.006730  0.004423  0.008306  0.008416   \n",
       "w40               0.029439    ...     0.081844 -0.002740 -0.107450 -0.014984   \n",
       "w50               0.114769    ...    -0.007062  0.018065  0.023334 -0.034051   \n",
       "w60              -0.113408    ...    -0.016810 -0.045815  0.037189  0.020716   \n",
       "casual_mode       0.149950    ...     0.019587  0.075597 -0.056912  0.003375   \n",
       "alternative_mode  0.070794    ...     0.030409  0.065007 -0.052062  0.033419   \n",
       "event_mode        0.005627    ...     0.040445  0.040315 -0.056367  0.007871   \n",
       "BoosterUsed      -0.011285    ...    -0.003806 -0.016379  0.016618 -0.014334   \n",
       "LevelTime         0.214636    ...    -0.009962  0.007174  0.009220 -0.019540   \n",
       "Percentage       -0.196650    ...     0.010804 -0.000374 -0.015072  0.023854   \n",
       "AD                0.001897    ...    -0.000319 -0.001374 -0.011000  0.083920   \n",
       "...                    ...    ...          ...       ...       ...       ...   \n",
       "RO                0.041862    ...    -0.002218 -0.009545  0.057894 -0.008354   \n",
       "RS               -0.021841    ...    -0.000782 -0.003368  0.022485 -0.002947   \n",
       "RU               -0.007132    ...    -0.011274 -0.048520 -0.376081 -0.039749   \n",
       "SA               -0.016153    ...    -0.009713 -0.017595  0.241380 -0.036583   \n",
       "SD                0.013437    ...    -0.000319 -0.001374  0.009177 -0.001203   \n",
       "SE               -0.003609    ...    -0.001920 -0.008262  0.055161 -0.007230   \n",
       "SG                0.010265    ...    -0.000639 -0.002749  0.018357 -0.002406   \n",
       "SK               -0.003338    ...    -0.000714 -0.003074 -0.006551 -0.002690   \n",
       "SY                0.007548    ...    -0.002418 -0.010407  0.069483 -0.009108   \n",
       "TH               -0.002265    ...    -0.003009 -0.012951  0.062706 -0.011334   \n",
       "TJ               -0.006611    ...    -0.000319  0.073445 -0.011000 -0.001203   \n",
       "TM               -0.060569    ...    -0.002287 -0.009841 -0.078755 -0.008612   \n",
       "TN                0.014714    ...    -0.000452 -0.001944 -0.015557 -0.001701   \n",
       "TR                0.044523    ...    -0.014677 -0.059216 -0.464507 -0.053034   \n",
       "TW                0.031944    ...    -0.001865 -0.008028  0.046669 -0.007026   \n",
       "UA               -0.000411    ...    -0.003874 -0.016673 -0.104736 -0.000349   \n",
       "US               -0.010197    ...    -0.005937 -0.021388  0.153765  0.025017   \n",
       "UZ                0.011047    ...    -0.001893 -0.008146 -0.065189 -0.007129   \n",
       "VN                0.014391    ...    -0.005341 -0.004586  0.148506 -0.020116   \n",
       "YE               -0.005367    ...    -0.000319 -0.001374  0.009177 -0.001203   \n",
       "ZA               -0.003141    ...     1.000000 -0.004348  0.029034 -0.003806   \n",
       "de               -0.003333    ...    -0.004348  1.000000 -0.149773 -0.016379   \n",
       "en               -0.011453    ...     0.029034 -0.149773  1.000000 -0.131077   \n",
       "es               -0.040716    ...    -0.003806 -0.016379 -0.131077  1.000000   \n",
       "fr                0.024714    ...    -0.005381 -0.023158 -0.185336 -0.020268   \n",
       "it               -0.026308    ...    -0.006357 -0.027359 -0.218952 -0.023944   \n",
       "pt-BR             0.008603    ...    -0.004712 -0.020278 -0.162286 -0.017747   \n",
       "ru               -0.013653    ...    -0.013768 -0.059253 -0.474202 -0.051857   \n",
       "tr                0.042872    ...    -0.014559 -0.062660 -0.501462 -0.054838   \n",
       "zh-CN            -0.009883    ...    -0.001781 -0.007664 -0.061338 -0.006708   \n",
       "\n",
       "                        fr        it     pt-BR        ru        tr     zh-CN  \n",
       "Unnamed: 0        0.042495  0.020833 -0.024485 -0.000096  0.014889  0.007735  \n",
       "adOption         -0.017401  0.005316  0.009388 -0.037771  0.036795 -0.023926  \n",
       "daysSinceInstall  0.016796 -0.000975 -0.044980  0.034922  0.011442  0.027481  \n",
       "hasEnoughCoin    -0.034151  0.004771 -0.016702 -0.027435  0.051418  0.032885  \n",
       "levelMode         0.008583  0.038964  0.003580 -0.021740 -0.006442  0.023039  \n",
       "levelNumber      -0.019599  0.022720 -0.022659 -0.025153  0.078044 -0.004977  \n",
       "numFails          0.019830  0.003028  0.019821  0.016979  0.027614  0.004063  \n",
       "percentageLeft    0.018664 -0.000591 -0.011363 -0.009842 -0.015377 -0.006644  \n",
       "platform         -0.020286 -0.042101 -0.105236  0.193477 -0.030746  0.057036  \n",
       "playTime          0.024714 -0.026308  0.008603 -0.013653  0.042872 -0.009883  \n",
       "sessions          0.001384  0.006984 -0.033244  0.002763  0.062086 -0.013833  \n",
       "twentileLeft      0.009757  0.002896 -0.005913 -0.008119 -0.003233 -0.015668  \n",
       "target            0.000762  0.002330 -0.004576 -0.011765  0.039558 -0.005909  \n",
       "4                 0.022930 -0.009123 -0.021502  0.015703  0.009649  0.025857  \n",
       "5                 0.004441  0.001358 -0.003719  0.009230  0.000181  0.002667  \n",
       "6                -0.028090  0.007909  0.025876 -0.025707 -0.010056 -0.029229  \n",
       "w0                0.058514  0.050241 -0.037059  0.038780 -0.063148  0.038759  \n",
       "w10              -0.000549  0.011043 -0.028991  0.022540 -0.041462  0.065795  \n",
       "w20              -0.023132  0.003738 -0.010374  0.012256  0.012229 -0.010002  \n",
       "w30               0.012592  0.004289 -0.024513 -0.012480  0.000394 -0.011861  \n",
       "w40               0.004818  0.008860 -0.004147  0.054878  0.090957 -0.012615  \n",
       "w50              -0.031199 -0.064098  0.019208 -0.014855  0.028540 -0.013235  \n",
       "w60              -0.001211  0.021394  0.028230 -0.038133 -0.020668 -0.019480  \n",
       "casual_mode      -0.016513  0.012423 -0.029890 -0.025052  0.084917 -0.010015  \n",
       "alternative_mode -0.004295 -0.002204 -0.019990 -0.002592  0.048286 -0.000996  \n",
       "event_mode       -0.015316  0.017118  0.002860  0.013449  0.044740 -0.023358  \n",
       "BoosterUsed       0.010911  0.007186  0.017629 -0.019030 -0.009662  0.008604  \n",
       "LevelTime        -0.003618 -0.018529 -0.007435 -0.007721  0.013413 -0.004892  \n",
       "Percentage       -0.000839  0.014570  0.000135  0.014603 -0.008819  0.001248  \n",
       "AD               -0.001701 -0.002009 -0.001489 -0.004352 -0.004602 -0.000563  \n",
       "...                    ...       ...       ...       ...       ...       ...  \n",
       "RO               -0.011812 -0.013954 -0.010343 -0.022251 -0.031960 -0.003909  \n",
       "RS               -0.004167 -0.004923 -0.003649 -0.010662 -0.011275 -0.001379  \n",
       "RU               -0.060041 -0.067599 -0.052574  0.799535 -0.162453 -0.019871  \n",
       "SA               -0.038559 -0.051718 -0.017902 -0.127397 -0.124693 -0.017119  \n",
       "SD               -0.001701 -0.002009 -0.001489 -0.004352 -0.004602 -0.000563  \n",
       "SE               -0.010223 -0.012078 -0.008952 -0.026157 -0.027661 -0.003383  \n",
       "SG               -0.003402 -0.004019 -0.002979 -0.008705 -0.009205 -0.001126  \n",
       "SK               -0.003804 -0.004494 -0.003331  0.027235 -0.010292 -0.001259  \n",
       "SY               -0.012878 -0.015213 -0.011276 -0.032949 -0.034843 -0.004262  \n",
       "TH                0.016659 -0.018933 -0.014033 -0.023306 -0.043361 -0.005304  \n",
       "TJ               -0.001701 -0.002009 -0.001489 -0.004352 -0.004602 -0.000563  \n",
       "TM               -0.012177 -0.014386 -0.010663  0.142874 -0.010595 -0.004030  \n",
       "TN                0.083940 -0.002842 -0.002106 -0.006155 -0.006509 -0.000796  \n",
       "TR               -0.058826 -0.092343 -0.068444 -0.191995  0.935936 -0.025869  \n",
       "TW               -0.009934 -0.011736 -0.008699 -0.025418 -0.026879  0.058519  \n",
       "UA               -0.020632 -0.024374 -0.018066  0.237592 -0.055823 -0.006828  \n",
       "US               -0.028222 -0.037356 -0.027688 -0.076304 -0.085555 -0.010465  \n",
       "UZ               -0.010080 -0.011908 -0.008826  0.137470 -0.027273 -0.003336  \n",
       "VN               -0.028443 -0.033602 -0.024906 -0.072775 -0.076958 -0.009413  \n",
       "YE               -0.001701 -0.002009 -0.001489 -0.004352 -0.004602 -0.000563  \n",
       "ZA               -0.005381 -0.006357 -0.004712 -0.013768 -0.014559 -0.001781  \n",
       "de               -0.023158 -0.027359 -0.020278 -0.059253 -0.062660 -0.007664  \n",
       "en               -0.185336 -0.218952 -0.162286 -0.474202 -0.501462 -0.061338  \n",
       "es               -0.020268 -0.023944 -0.017747 -0.051857 -0.054838 -0.006708  \n",
       "fr                1.000000 -0.033855 -0.025093 -0.073323 -0.077538 -0.009484  \n",
       "it               -0.033855  1.000000 -0.029645 -0.086622 -0.091602 -0.011205  \n",
       "pt-BR            -0.025093 -0.029645  1.000000 -0.064204 -0.067894 -0.008305  \n",
       "ru               -0.073323 -0.086622 -0.064204  1.000000 -0.198389 -0.024267  \n",
       "tr               -0.077538 -0.091602 -0.067894 -0.198389  1.000000 -0.025662  \n",
       "zh-CN            -0.009484 -0.011205 -0.008305 -0.024267 -0.025662  1.000000  \n",
       "\n",
       "[130 rows x 130 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = os_data_X[features_chosen_rfe]\n",
    "y = os_data_y['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Implementing Logistic Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.626138\n",
      "         Iterations: 35\n",
      "                            Results: Logit\n",
      "=======================================================================\n",
      "Model:                Logit              Pseudo R-squared:   0.097     \n",
      "Dependent Variable:   y                  AIC:                15104.9126\n",
      "Date:                 2018-11-14 12:22   BIC:                15178.8775\n",
      "No. Observations:     12046              Log-Likelihood:     -7542.5   \n",
      "Df Model:             9                  LL-Null:            -8349.7   \n",
      "Df Residuals:         12036              LLR p-value:        0.0000    \n",
      "Converged:            0.0000             Scale:              1.0000    \n",
      "No. Iterations:       35.0000                                          \n",
      "-----------------------------------------------------------------------\n",
      "               Coef.    Std.Err.     z    P>|z|     [0.025     0.975]  \n",
      "-----------------------------------------------------------------------\n",
      "adOption        1.4501     0.0454 31.9603 0.0000      1.3612     1.5391\n",
      "hasEnoughCoin  -0.0347     0.0268 -1.2972 0.1946     -0.0872     0.0177\n",
      "AL             -3.7696     1.9401 -1.9429 0.0520     -7.5722     0.0330\n",
      "BD            -21.5388 15673.0606 -0.0014 0.9989 -30740.1731 30697.0954\n",
      "GR             -1.8967     0.5048 -3.7573 0.0002     -2.8861    -0.9073\n",
      "MU              2.0094     0.9583  2.0969 0.0360      0.1313     3.8876\n",
      "MY             -1.7621     0.3933 -4.4800 0.0000     -2.5331    -0.9912\n",
      "OM              1.6033     0.5697  2.8144 0.0049      0.4867     2.7199\n",
      "RS            -21.1557 12310.6989 -0.0017 0.9986 -24149.6821 24107.3708\n",
      "SY             -2.5837     0.4379 -5.9007 0.0000     -3.4419    -1.7255\n",
      "=======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "log_model = sm.Logit(y, X)\n",
    "\n",
    "result = log_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get rid of features which represents p > alpha(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_pvalue_features = ['adOption','GR','MU','MY','OM','SY']  #meh only remaining features... not cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=os_data_X[post_pvalue_features]\n",
    "y=os_data_y['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.627459\n",
      "         Iterations 6\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.095     \n",
      "Dependent Variable: y                AIC:              15128.7480\n",
      "Date:               2018-11-14 12:30 BIC:              15173.1269\n",
      "No. Observations:   12046            Log-Likelihood:   -7558.4   \n",
      "Df Model:           5                LL-Null:          -8349.7   \n",
      "Df Residuals:       12040            LLR p-value:      0.0000    \n",
      "Converged:          1.0000           Scale:            1.0000    \n",
      "No. Iterations:     6.0000                                       \n",
      "------------------------------------------------------------------\n",
      "               Coef.   Std.Err.     z     P>|z|    [0.025   0.975]\n",
      "------------------------------------------------------------------\n",
      "adOption       1.4167    0.0407  34.7882  0.0000   1.3369   1.4965\n",
      "GR            -1.9019    0.5043  -3.7715  0.0002  -2.8902  -0.9135\n",
      "MU             1.9678    0.9551   2.0603  0.0394   0.0958   3.8398\n",
      "MY            -1.7781    0.3926  -4.5290  0.0000  -2.5476  -1.0086\n",
      "OM             1.5748    0.5680   2.7727  0.0056   0.4616   2.6879\n",
      "SY            -2.5806    0.4366  -5.9111  0.0000  -3.4363  -1.7249\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "people coutnties conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.72\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1503  256]\n",
      " [ 741 1114]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.67      0.85      0.75      1759\n",
      "       True       0.81      0.60      0.69      1855\n",
      "\n",
      "avg / total       0.74      0.72      0.72      3614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine results yet again the same problem.  adWatch is fully dependent on adOption.\n",
    "\n",
    "At following you may see how model performs once we took of adOption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2566,    5],\n",
       "       [ 394,    8]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.87      1.00      0.93      2145\n",
      "       True       0.00      0.00      0.00       332\n",
      "\n",
      "avg / total       0.75      0.87      0.80      2477\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
